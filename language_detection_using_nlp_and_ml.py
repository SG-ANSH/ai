# -*- coding: utf-8 -*-
"""language-detection-using-nlp-and-ml.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13UIaKSzBthHhDhx9VqHwnDpvx9xnTs_d

# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Language Detection using NLP and ML</b></p>

![image.png](attachment:image.png)

# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>About Dataset</b></p>

- In this project, a model that predicts the language of an input text is created.

- The dataset contains texts from 17 different languages.

Dataset: https://www.kaggle.com/datasets/basilb2s/language-detection

# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Importing Basic Libraries and the Dataset</b></p>
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings("ignore")

df= pd.read_csv("Language_Detection.csv")
df.head(10)

"""# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Understanding the Dataset</b></p>"""

df.shape

df.info()

df.isnull().sum()

df[df.duplicated()]

len(df[df.duplicated()])

"""There are 66 duplicate rows, let's drop them..."""

df.drop(df[df.duplicated()].index, axis=0, inplace=True)

df.shape

"""The dataset contains texts from 17 different languages:"""

df["Language"].nunique()

"""How many rows belong to each language?:"""

df["Language"].value_counts()

"""visually...:"""

plt.figure(figsize=(20,8))

total= float(len(df['Language']))
ax= sns.countplot(x= 'Language', data= df, order= df['Language'].value_counts().index, palette= 'magma')

for p in ax.patches:
    percentage= '{:.2f}%'.format(100 * p.get_height()/total)
    x= p.get_x() + p.get_width()
    y= p.get_height()
    ax.annotate(percentage, (x, y), fontsize=16, ha='center')

plt.title('Counts and Percentages of Languages', fontsize=24)
plt.xlabel("Language",fontsize=20)
plt.ylabel("Count", fontsize=20)
plt.xticks(size= 18, rotation=90)
plt.show()

language= df['Language'].value_counts().reset_index()
language

plt.figure(figsize=(10,10))

#create pie chart
labels= language['index']

plt.pie(language["Language"], labels= labels, autopct='%.1f%%', textprops={'fontsize': 15})

plt.show()

"""# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Text Preprocessing</b></p>

Let's create a new column for cleaned text:
"""

df1= df.copy()
df1['cleaned_Text']= ""
df1

import re
def clean_function(Text):
    # removing the symbols and numbers
    Text = re.sub(r'[\([{})\]!@#$,"%^*?:;~`0-9]', ' ', Text)

    # converting the text to lower case
    Text = Text.lower()
    Text = re.sub('http\S+\s*', ' ', Text)  # remove URLs
    Text = re.sub('RT|cc', ' ', Text)  # remove RT and cc
    Text = re.sub('#\S+', '', Text)  # remove hashtags
    Text = re.sub('@\S+', '  ', Text)  # remove mentions
    Text = re.sub('\s+', ' ', Text)  # remove extra whitespace

    return Text

"""and let's clean:"""

df1['cleaned_Text'] = df1['Text'].apply(lambda x: clean_function(x))
df1

"""# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Separating Independent and Dependent Features</b></p>

Text data is the independent variable and the language name is the dependent variable.
"""

X= df1["cleaned_Text"]
y= df1["Language"]

"""# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Label Encoding</b></p>

Language names make up our output variable, which is a categorical variable. We are conducting label encoding on that output variable because we should need to turn it into a numerical form for training the model. We are importing LabelEncoder from sklearn for this procedure.
"""

from sklearn.preprocessing import LabelEncoder

encoder= LabelEncoder()

y= encoder.fit_transform(y)

"""# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Bag of Words</b></p>

As is common knowledge, both the input and the output features must be in numerical form. Therefore, using CountVectorizer to build a Bag of Words model, we are converting text into numerical form.
"""

from sklearn.feature_extraction.text import CountVectorizer
CV= CountVectorizer()
X= CV.fit_transform(X).toarray()
X.shape

"""# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Splitting Train and Test Data</b></p>"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=42)

"""# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Building Model and Training</b></p>"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB

models = {
    'K-Nearest Neighbors' : KNeighborsClassifier(),
    'Random Forest' : RandomForestClassifier(),
    'MNB' : MultinomialNB()
}

# Commented out IPython magic to ensure Python compatibility.
# %%time
# for name, model in models.items():
#     print(f'{name} training started...')
#     model.fit(X_train, y_train)
#     print(f'{name} trained')

"""# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Model Evaluation</b></p>"""

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix as CM
from sklearn.metrics import classification_report

# Commented out IPython magic to ensure Python compatibility.
# %%time
# for name in models:
#     acc_score= round(accuracy_score(y_test, models.get(name).predict(X_test)), 3)
#     print(f'{name} accuracy score :  {acc_score}')

"""The accuracy of the MNB model is 0.98 which is very good and our model is performing well."""

for name in models:
    print(f'{name} classification report')
    print("-------------------------------")
    print(classification_report(y_test, models.get(name).predict(X_test)))
    print("******************************")
    print(" ")

for name in models:
    print(f'{name} ConfusionMatrix')
    predictions= models.get(name).predict(X_test)
    score = round(accuracy_score(y_test, models.get(name).predict(X_test)), 3)
    confusionMatrix = CM(y_test, models.get(name).predict(X_test))
    sns.heatmap(confusionMatrix, annot=True, fmt=".0f")
    plt.xlabel('Actual Values')
    plt.ylabel('Prediction Values')
    plt.title('Accuracy Score: {0}'.format(score), size = 15)
    plt.show()
    print("******************************")
    print(" ")

"""# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Predictions</b></p>"""

def prediction(text):
    x= CV.transform([text]).toarray()
    lang= model.predict(x)
    lang= encoder.inverse_transform(lang)
    print("This word/sentence contains {} word(s).".format(lang[0]))

prediction("Your memory improves as you learn a language. In addition, since your brain will automatically translate, it enables the brain to work in a versatile way and contributes to the development of your abilities.")

prediction("L'apprentissage d'une langue amÃ©liore la mÃ©moire. De plus, comme votre cerveau traduira automatiquement, cela lui permet de travailler de maniÃ¨re polyvalente et contribue au dÃ©veloppement de vos compÃ©tences.")

prediction("Î— Î¼Î½Î®Î¼Î· ÏƒÎ±Ï‚ Î²ÎµÎ»Ï„Î¹ÏÎ½ÎµÏ„Î±Î¹ ÎºÎ±Î¸ÏÏ‚ Î¼Î±Î¸Î±Î¯Î½ÎµÏ„Îµ Î¼Î¹Î± Î³Î»ÏÏƒÏƒÎ±. Î•Ï€Î¹Ï€Î»Î­Î¿Î½, Î´ÎµÎ´Î¿Î¼Î­Î½Î¿Ï… ÏŒÏ„Î¹ Î¿ ÎµÎ³ÎºÎ­Ï†Î±Î»ÏŒÏ‚ ÏƒÎ±Ï‚ Î¸Î± Î¼ÎµÏ„Î±Ï†ÏÎ±ÏƒÏ„ÎµÎ¯ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±, Î´Î¯Î½ÎµÎ¹ Ï„Î· Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„Î± ÏƒÏ„Î¿Î½ ÎµÎ³ÎºÎ­Ï†Î±Î»Î¿ Î½Î± Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯ Î¼Îµ ÎµÏ…Î­Î»Î¹ÎºÏ„Î¿ Ï„ÏÏŒÏ€Î¿ ÎºÎ±Î¹ ÏƒÏ…Î¼Î²Î¬Î»Î»ÎµÎ¹ ÏƒÏ„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï„Ï‰Î½ Î¹ÎºÎ±Î½Î¿Ï„Î®Ï„Ï‰Î½ ÏƒÎ±Ï‚.")

prediction("à²¨à³€à²µà³ à²­à²¾à²·à³†à²¯à²¨à³à²¨à³ à²•à²²à²¿à²¤à²‚à²¤à³† à²¨à²¿à²®à³à²® à²¸à³à²®à²°à²£à³†à²¯à³ à²¸à³à²§à²¾à²°à²¿à²¸à³à²¤à³à²¤à²¦à³†. à²¹à³†à²šà³à²šà³à²µà²°à²¿à²¯à²¾à²—à²¿, à²¨à²¿à²®à³à²® à²®à³†à²¦à³à²³à³ à²¸à³à²µà²¯à²‚à²šà²¾à²²à²¿à²¤à²µà²¾à²—à²¿ à²…à²¨à³à²µà²¾à²¦à²¿à²¸à³à²µà³à²¦à²°à²¿à²‚à²¦, à²‡à²¦à³ à²®à³†à²¦à³à²³à²¿à²—à³† à²¬à²¹à³à²®à³à²– à²°à³€à²¤à²¿à²¯à²²à³à²²à²¿ à²•à³†à²²à²¸ à²®à²¾à²¡à²²à³ à²…à²¨à³à²µà³ à²®à²¾à²¡à²¿à²•à³Šà²¡à³à²¤à³à²¤à²¦à³† à²®à²¤à³à²¤à³ à²¨à²¿à²®à³à²® à²¸à²¾à²®à²°à³à²¥à³à²¯à²—à²³ à²¬à³†à²³à²µà²£à²¿à²—à³†à²—à³† à²•à³Šà²¡à³à²—à³† à²¨à³€à²¡à³à²¤à³à²¤à²¦à³†.")

prediction("Bir dil Ã¶ÄŸrenirken hafÄ±zanÄ±z geliÅŸir. AyrÄ±ca beyniniz otomatik olarak Ã§eviri yapacaÄŸÄ± iÃ§in beynin Ã§ok yÃ¶nlÃ¼ Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar ve yeteneklerinizin geliÅŸimine katkÄ±da bulunur.")

"""# <p style="background-color:#C71585;font-family:Georgia;font-size:125%;color:white;text-align:left;border-radius:20px 20px;"><b>Model Saving</b></p>"""

import pickle
pickle.dump(model, open("model.pkl", "wb"))
pickle.dump(CV, open("transform.pkl", "wb"))

"""<div style="color:white; font-size:125%; text-align:left; display:fill; border-radius:5px; background-color:#C71585; overflow:hidden">Thanks for reading. I hope you enjoy it and that it was helpful to you.<br>Please don't forget to follow me and give an upvote on</br>
ğŸ‘‡ğŸ‘‡ğŸ‘‡
</div>

**<a href="https://www.kaggle.com/yaseminturker/" target="_blank" rel="noopener noreferrer">[Kaggle]</a> |
<a href="https://github.com/yaseminturker" target="_blank" rel="noopener noreferrer">[GitHub]</a> |
<a href="https://www.linkedin.com/in/yasemin-turker/" target="_blank" rel="noopener noreferrer">[Linkedin]</a>**
"""